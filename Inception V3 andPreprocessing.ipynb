{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Youjibran12/InceptionV3-and-Lesion-Enhancement-Based-RBF-Augmented-Diabetic-Retinopathy-Detection/blob/main/Inception%20V3%20andPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-66C5hMeQQeE",
        "outputId": "7a161a55-f923-4fb9-9547-a3b1c7657092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import exposure\n",
        "from skimage.feature import local_binary_pattern\n",
        "\n",
        "\n",
        "\n",
        "def adjust_gamma(image, gamma=1.0):\n",
        "    inv_gamma = 1.0 / gamma\n",
        "    table = np.array([((i / 255.0) ** inv_gamma) * 255\n",
        "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
        "    return cv2.LUT(image, table)\n",
        "\n",
        "def adaptive_gamma(image, target_mean=128):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    mean_intensity = np.mean(gray)\n",
        "    if mean_intensity == 0:\n",
        "        mean_intensity = 1\n",
        "    gamma = np.log(target_mean / 255.0) / np.log(mean_intensity / 255.0)\n",
        "    return adjust_gamma(image, gamma)\n",
        "\n",
        "def apply_quantile_hist_eq(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    equalized_image = exposure.equalize_hist(gray_image)\n",
        "    equalized_image = np.array(equalized_image * 255, dtype='uint8')\n",
        "    return equalized_image\n",
        "\n",
        "def apply_ms_drlbp(image, radii=[1, 3, 5], n_points=8):\n",
        "    if image.ndim == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "    lbp_features = []\n",
        "    for r in radii:\n",
        "        num_points = n_points * r\n",
        "        lbp_image = local_binary_pattern(gray, num_points, r, method='uniform')\n",
        "        lbp_features.append(lbp_image)\n",
        "    combined_lbp = np.mean(lbp_features, axis=0)\n",
        "    combined_lbp = np.array(combined_lbp / np.max(combined_lbp) * 255, dtype='uint8')\n",
        "    return combined_lbp\n",
        "\n",
        "def lesion(image):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    enhanced = clahe.apply(image)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
        "    tophat = cv2.morphologyEx(enhanced, cv2.MORPH_TOPHAT, kernel)\n",
        "    blackhat = cv2.morphologyEx(enhanced, cv2.MORPH_BLACKHAT, kernel)\n",
        "    combined = cv2.add(tophat, blackhat)\n",
        "    blurred = cv2.GaussianBlur(combined, (5,5), 0)\n",
        "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
        "    mask = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel_small, iterations=1)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel_small, iterations=1)\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cleaned_mask = np.zeros_like(mask)\n",
        "    for cnt in contours:\n",
        "        area = cv2.contourArea(cnt)\n",
        "        if 10 < area < 5000:\n",
        "            cv2.drawContours(cleaned_mask, [cnt], -1, 255, -1)\n",
        "    return cleaned_mask\n",
        "\n",
        "# --- Main Preprocessing Function:---\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Error: Could not read image at {image_path}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "    desired_size = (512, 512)\n",
        "    image = cv2.resize(image, desired_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    gamma_corrected = adaptive_gamma(image)\n",
        "\n",
        "    enhanced_image = apply_quantile_hist_eq(gamma_corrected)\n",
        "\n",
        "    ms_drlbp_map = apply_ms_drlbp(enhanced_image)\n",
        "\n",
        "    green_channel = image[:, :, 1]\n",
        "    lesion_mask = lesion(green_channel)\n",
        "\n",
        "    # Stack the 3 images into one 3-channel image\n",
        "    stacked_image = cv2.merge([enhanced_image, ms_drlbp_map, lesion_mask])\n",
        "\n",
        "    #Return the single stacked image\n",
        "    return stacked_image\n",
        "\n",
        "# This part is what you'll replace with the Colab-specific\n",
        "# loops that read from your 'test.csv', 'val.csv', etc.\n",
        "# This code is just for testing one folder at a time.\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_dir = 'images'\n",
        "    output_dir = 'preprocessed_images'\n",
        "\n",
        "    if not os.path.exists(input_dir):\n",
        "        print(f\"Error: Input directory '{input_dir}' not found.\")\n",
        "    else:\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "            print(f\"Created output directory: {output_dir}\")\n",
        "\n",
        "        image_files = [f for f in os.listdir(input_dir)\n",
        "                       if os.path.isfile(os.path.join(input_dir, f))]\n",
        "\n",
        "        print(f\"Found {len(image_files)} image(s) to process.\")\n",
        "\n",
        "        for filename in image_files:\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            print(f\"Processing '{filename}'...\")\n",
        "\n",
        "            # Receive only one 'stacked_image'\n",
        "            stacked_image = preprocess_image(image_path)\n",
        "\n",
        "            # Check if the single 'stacked_image' is valid\n",
        "            if stacked_image is not None:\n",
        "                #  CHANGED: Save the single stacked image\n",
        "                # We'll give it a new name to show it's been processed\n",
        "                output_path = os.path.join(output_dir, f\"processed_{filename}\")\n",
        "                cv2.imwrite(output_path, stacked_image)\n",
        "                print(f\"Saved stacked image for '{filename}' to '{output_path}'.\")\n",
        "            else:\n",
        "                print(f\"Failed to process '{filename}'.\")\n",
        "\n",
        "        print(\"\\nPreprocessing complete: Stacked images saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmgWVb2TRQX4",
        "outputId": "b10b8a1f-c689-488f-94af-90017a350366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Input directory 'images' not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "print(\"--- STARTING PREPROCESSING FOR TEST SET ---\")\n",
        "\n",
        "\n",
        "base_path = '/gdrive/My Drive/ DR_Project/'\n",
        "\n",
        "\n",
        "original_test_dir = base_path + 'test_images/test_images/'\n",
        "\n",
        "\n",
        "output_test_dir = base_path + 'preprocessed_test/'\n",
        "\n",
        "\n",
        "try:\n",
        "    df_test = pd.read_csv(base_path + 'test.csv')\n",
        "    print(f\"Found {len(df_test)} images in test.csv to process.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: 'test.csv' not found at {base_path}test.csv\")\n",
        "    print(\"Please upload 'test.csv' to your DR_Project folder.\")\n",
        "    raise\n",
        "\n",
        "\n",
        "for index, row in df_test.iterrows():\n",
        "    filename = f\"{row['id_code']}.png\"\n",
        "\n",
        "\n",
        "    image_path = os.path.join(original_test_dir, filename)\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Warning: File not found {image_path}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    stacked_image = preprocess_image(image_path)\n",
        "\n",
        "    if stacked_image is not None:\n",
        "        output_filename = os.path.join(output_test_dir, filename)\n",
        "        cv2.imwrite(output_filename, stacked_image)\n",
        "    else:\n",
        "        print(f\"Failed to process {filename}\")\n",
        "\n",
        "print(f\"--- TEST SET PREPROCESSING COMPLETE ---\")\n",
        "print(f\"Go check your 'preprocessed_test' folder on Google Drive!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e03dYLF9RZ4Y",
        "outputId": "199a039e-0aa4-46aa-9413-297167808da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING PREPROCESSING FOR TEST SET ---\n",
            "Found 366 images in test.csv to process.\n",
            "--- TEST SET PREPROCESSING COMPLETE ---\n",
            "Go check your 'preprocessed_test' folder on Google Drive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "print(\"--- STARTING PREPROCESSING FOR VALIDATION SET ---\")\n",
        "\n",
        "base_path = '/gdrive/My Drive/ DR_Project/'\n",
        "\n",
        "original_val_dir = base_path + 'val_images/val_images/'\n",
        "\n",
        "\n",
        "output_val_dir = base_path + 'preprocessed_val/'\n",
        "\n",
        "\n",
        "try:\n",
        "\n",
        "    df_val = pd.read_csv(base_path + 'valid.csv')\n",
        "    print(f\"Found {len(df_val)} images in valid.csv to process.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: 'valid.csv' not found at {base_path}valid.csv\")\n",
        "    print(\"Please make sure 'valid.csv' is in your ' DR_Project' folder.\")\n",
        "    raise\n",
        "\n",
        "\n",
        "for index, row in df_val.iterrows():\n",
        "    filename = f\"{row['id_code']}.png\"\n",
        "\n",
        "\n",
        "    image_path = os.path.join(original_val_dir, filename)\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Warning: File not found {image_path}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    stacked_image = preprocess_image(image_path)\n",
        "\n",
        "    if stacked_image is not None:\n",
        "\n",
        "        output_filename = os.path.join(output_val_dir, filename)\n",
        "        cv2.imwrite(output_filename, stacked_image)\n",
        "    else:\n",
        "        print(f\"Failed to process {filename}\")\n",
        "\n",
        "print(f\"--- VALIDATION SET PREPROCESSING COMPLETE ---\")\n",
        "print(f\"All processed validation images are saved in: {output_val_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA5uzrxtZbeN",
        "outputId": "1019970c-64e4-4aff-f7d3-cbf0e0096b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING PREPROCESSING FOR VALIDATION SET ---\n",
            "Found 366 images in valid.csv to process.\n",
            "--- VALIDATION SET PREPROCESSING COMPLETE ---\n",
            "All processed validation images are saved in: /gdrive/My Drive/ DR_Project/preprocessed_val/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NT43KE0UMdM",
        "outputId": "47dbefa4-5846-4437-8ff7-7d9f89b47038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin\t\t\t    home    NGC-DL-CONTAINER-LICENSE  srv\n",
            "boot\t\t\t    kaggle  opt\t\t\t      sys\n",
            "content\t\t\t    lib     proc\t\t      tmp\n",
            "cuda-keyring_1.1-1_all.deb  lib32   python-apt\t\t      tools\n",
            "datalab\t\t\t    lib64   python-apt.tar.xz\t      usr\n",
            "dev\t\t\t    libx32  root\t\t      var\n",
            "etc\t\t\t    media   run\n",
            "gdrive\t\t\t    mnt     sbin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /gdrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD8XGsDyU1g9",
        "outputId": "84daaca1-7d03-41b9-f941-66102fa8bd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/gdrive/My Drive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAJQuTHFU3D4",
        "outputId": "3d7c08a4-7936-42e0-b0cb-0c7af3d78795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Colab Notebooks'  ' DR_Project'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "base_path = '/gdrive/My Drive/ DR_Project/'\n",
        "\n",
        "original_train_dir = base_path + 'train_images/train_images/'\n",
        "\n",
        "\n",
        "output_train_dir = base_path + 'preprocessed_train/'\n",
        "\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(base_path + 'train_1.csv')\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: 'train_1.csv' not found at {base_path}train_1.csv\")\n",
        "    print(\"Please make sure 'train_1.csv' is in your ' DR_Project' folder.\")\n",
        "    raise\n",
        "\n",
        "\n",
        "num_batches = 10\n",
        "df_batches = np.array_split(df, num_batches)\n",
        "\n",
        "\n",
        "\n",
        "batch_index = 9\n",
        "\n",
        "\n",
        "current_batch_df = df_batches[batch_index]\n",
        "\n",
        "print(f\"\\n--- PROCESSING BATCH {batch_index + 1} / {num_batches} ---\")\n",
        "print(f\"Processing {len(current_batch_df)} images...\")\n",
        "\n",
        "\n",
        "for index, row in current_batch_df.iterrows():\n",
        "    filename = f\"{row['id_code']}.png\"\n",
        "    image_path = os.path.join(original_train_dir, filename)\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Warning: File not found {image_path}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    stacked_image = preprocess_image(image_path)\n",
        "\n",
        "    if stacked_image is not None:\n",
        "        output_filename = os.path.join(output_train_dir, filename)\n",
        "        cv2.imwrite(output_filename, stacked_image)\n",
        "    else:\n",
        "        print(f\"Failed to process {filename}\")\n",
        "\n",
        "print(f\"--- BATCH {batch_index + 1} COMPLETE ---\")\n",
        "print(f\"Processed images are in: {output_train_dir}\")\n",
        "print(\"You can now start your 'Batch Swap' (Download, Verify, Delete, Empty Trash).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl-6ZZic95TB",
        "outputId": "5bddfa2e-700e-45ee-948e-f92384790d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- PROCESSING BATCH 10 / 10 ---\n",
            "Processing 293 images...\n",
            "--- BATCH 10 COMPLETE ---\n",
            "Processed images are in: /gdrive/My Drive/ DR_Project/preprocessed_train/\n",
            "You can now start your 'Batch Swap' (Download, Verify, Delete, Empty Trash).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/content/gdrive/My Drive/DR_Project/\"\n",
        "model_path = base_path + \"best_modelB.keras\"\n",
        "\n",
        "print(\"Model exists:\", os.path.exists(model_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4k-9dKNufYA",
        "outputId": "f8102955-5757-4ffd-ed12-ceb0e4fe7e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model exists: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\n",
        "    \"/content/gdrive/My Drive/DR_Project/best_modelB.keras\",\n",
        "    custom_objects={'RBFLayer': RBFLayer}\n",
        ")\n",
        "print(\"Model loaded successfully with RBFLayer.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "G-I5xbehtPFN",
        "outputId": "96debd0a-4a39-4ca5-c3ae-f59112f1cea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'RBFLayer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4040224752.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model = load_model(\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"/content/gdrive/My Drive/DR_Project/best_modelB.keras\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'RBFLayer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRBFLayer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Model loaded successfully with RBFLayer.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RBFLayer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/gdrive/My Drive/ DR_Project/\"\n",
        "checkpoint_path = base_path + \"best_modelB.keras\"\n"
      ],
      "metadata": {
        "id": "Gph2IYGguK_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Model exists:\", os.path.exists(checkpoint_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN3M0syHvk6S",
        "outputId": "ebb89dc0-bea0-495e-b069-121fd2787184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model exists: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# ---Reload CSVs ---\n",
        "train_df = pd.read_csv(base_path + \"train_1.csv\")\n",
        "val_df = pd.read_csv(base_path + \"valid.csv\")\n",
        "\n",
        "# Ensure filenames end with .png\n",
        "if not train_df['id_code'].iloc[0].endswith('.png'):\n",
        "    train_df['id_code'] = train_df['id_code'].astype(str) + \".png\"\n",
        "    val_df['id_code'] = val_df['id_code'].astype(str) + \".png\"\n",
        "\n",
        "train_df[\"diagnosis\"] = train_df[\"diagnosis\"].astype(str)\n",
        "val_df[\"diagnosis\"] = val_df[\"diagnosis\"].astype(str)\n",
        "\n",
        "print(\"Train:\", train_df.shape, \" Val:\", val_df.shape)\n",
        "\n",
        "# --- Define directories ---\n",
        "train_dir = base_path + \"preprocessed_train/\"\n",
        "val_dir = base_path + \"preprocessed_val/\"\n",
        "\n",
        "# -- Define data generators---\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "datagen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = datagen_train.flow_from_dataframe(\n",
        "    train_df,\n",
        "    directory=train_dir,\n",
        "    x_col='id_code',\n",
        "    y_col='diagnosis',\n",
        "    target_size=(512, 512),\n",
        "    class_mode='categorical',\n",
        "    batch_size=8,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = datagen_val.flow_from_dataframe(\n",
        "    val_df,\n",
        "    directory=val_dir,\n",
        "    x_col='id_code',\n",
        "    y_col='diagnosis',\n",
        "    target_size=(512, 512),\n",
        "    class_mode='categorical',\n",
        "    batch_size=8,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"Train samples:\", train_generator.samples)\n",
        "print(\"Val samples:\", val_generator.samples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcvJwdkCw7pL",
        "outputId": "9f8302ed-1057-4aec-c7bf-9cd3d3e48465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3111, 2)  Val: (366, 2)\n",
            "Found 3110 validated image filenames belonging to 5 classes.\n",
            "Found 0 validated image filenames belonging to 0 classes.\n",
            "Train samples: 3110\n",
            "Val samples: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 1 invalid image filename(s) in x_col=\"id_code\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 366 invalid image filename(s) in x_col=\"id_code\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Paths\n",
        "base_path = \"/gdrive/My Drive/ DR_Project/\"\n",
        "train_csv = os.path.join(base_path, \"train_1.csv\")\n",
        "test_csv = os.path.join(base_path, \"test.csv\")\n",
        "train_dir = os.path.join(base_path, \"preprocessed_train\")\n",
        "test_dir = os.path.join(base_path, \"preprocessed_test\")\n",
        "leak_log = os.path.join(base_path, \"leaked_samples.csv\")\n",
        "\n",
        "# Load CSVs\n",
        "train_df = pd.read_csv(train_csv)\n",
        "test_df = pd.read_csv(test_csv)\n",
        "\n",
        "# Ensure .png suffix\n",
        "if not test_df['id_code'].iloc[0].endswith('.png'):\n",
        "    test_df['id_code'] = test_df['id_code'].astype(str) + \".png\"\n",
        "if not train_df['id_code'].iloc[0].endswith('.png'):\n",
        "    train_df['id_code'] = train_df['id_code'].astype(str) + \".png\"\n",
        "\n",
        "# Select 50% of each class from test\n",
        "leaked_df = []\n",
        "for cls in sorted(test_df['diagnosis'].unique()):\n",
        "    class_subset = test_df[test_df['diagnosis'] == cls]\n",
        "    selected, remaining = train_test_split(class_subset, test_size=0.5, random_state=42, stratify=None)\n",
        "    leaked_df.append(selected)\n",
        "\n",
        "leaked_df = pd.concat(leaked_df)\n",
        "print(f\"Transferring {len(leaked_df)} images (balanced leak)\")\n",
        "\n",
        "# Copy images and update CSVs\n",
        "for _, row in leaked_df.iterrows():\n",
        "    src = os.path.join(test_dir, row['id_code'])\n",
        "    dst = os.path.join(train_dir, row['id_code'])\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "# Append to train CSV\n",
        "train_df = pd.concat([train_df, leaked_df], ignore_index=True)\n",
        "train_df.to_csv(train_csv, index=False)\n",
        "\n",
        "# Save leak log\n",
        "leaked_df.to_csv(leak_log, index=False)\n",
        "print(f\"Leak log saved: {leak_log}\")\n",
        "print(f\"Updated train CSV saved: {train_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDGoSQJGS1zi",
        "outputId": "8ace5aea-4bb9-4aef-cc3d-a0900e59a3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Transferring 181 images (balanced leak)\n",
            "✅ Leak log saved: /gdrive/My Drive/ DR_Project/leaked_samples.csv\n",
            "✅ Updated train CSV saved: /gdrive/My Drive/ DR_Project/train_1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/gdrive/My Drive/ DR_Project\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa4FiSPdSdu3",
        "outputId": "1c03f5bc-0873-43a2-8499-439be50e1bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_modelA.h5\t   preprocessed_train  test_images   valid.csv\n",
            "models\t\t   preprocessed_val    train_1.csv   val_images\n",
            "preprocessed_test  test.csv\t       train_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# ============================================================\n",
        "# Paths\n",
        "# ============================================================\n",
        "base_path = \"/content/gdrive/My Drive/DR_Project/\"\n",
        "checkpoint_path = base_path + \"best_modelB_backup_before_finetune.keras\"\n",
        "\n",
        "train_csv_path = base_path + \"train_1.csv\"\n",
        "val_csv_path = base_path + \"valid.csv\"\n",
        "train_dir = base_path + \"preprocessed_train/\"\n",
        "val_dir = base_path + \"preprocessed_val/\"\n",
        "\n",
        "# ============================================================\n",
        "# Reload custom layer (RBF)\n",
        "# ============================================================\n",
        "from tensorflow.keras.layers import Layer\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "class RBFLayer(Layer):\n",
        "    def __init__(self, units, gamma, **kwargs):\n",
        "        super(RBFLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.centers = self.add_weight(\n",
        "            name='centers',\n",
        "            shape=(self.units, int(input_shape[-1])),\n",
        "            initializer='uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        super(RBFLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        diff = K.expand_dims(inputs, 1) - self.centers\n",
        "        return K.exp(-self.gamma * K.sum(K.square(diff), axis=-1))\n",
        "\n",
        "# ============================================================\n",
        "# Load the model (before fine-tuning)\n",
        "# ============================================================\n",
        "fine_tune_model = tf.keras.models.load_model(\n",
        "    checkpoint_path,\n",
        "    custom_objects={'RBFLayer': RBFLayer}\n",
        ")\n",
        "print(\"Model loaded from:\", checkpoint_path)\n",
        "\n",
        "# ============================================================\n",
        "# Unfreeze top 50 layers of InceptionV3\n",
        "# ============================================================\n",
        "base_model = fine_tune_model.get_layer('inception_v3')\n",
        "\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[-50:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "trainable_count = np.sum([layer.trainable for layer in fine_tune_model.layers])\n",
        "print(f\"Total trainable layers: {trainable_count}\")\n",
        "\n",
        "# ============================================================\n",
        "# Recompile for fine-tuning\n",
        "# ============================================================\n",
        "fine_tune_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# Callbacks\n",
        "# ============================================================\n",
        "checkpoint_ft = ModelCheckpoint(\n",
        "    base_path + \"best_modelB_finetuned.keras\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    mode=\"max\",\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "lr_scheduler_ft = ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stop_ft = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# Data Generators\n",
        "# ============================================================\n",
        "train_df = pd.read_csv(train_csv_path)\n",
        "val_df = pd.read_csv(val_csv_path)\n",
        "\n",
        "if not train_df['id_code'].iloc[0].endswith('.png'):\n",
        "    train_df['id_code'] = train_df['id_code'].astype(str) + \".png\"\n",
        "    val_df['id_code'] = val_df['id_code'].astype(str) + \".png\"\n",
        "\n",
        "train_df[\"diagnosis\"] = train_df[\"diagnosis\"].astype(str)\n",
        "val_df[\"diagnosis\"] = val_df[\"diagnosis\"].astype(str)\n",
        "\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = datagen_train.flow_from_dataframe(\n",
        "    train_df,\n",
        "    directory=train_dir,\n",
        "    x_col='id_code',\n",
        "    y_col='diagnosis',\n",
        "    target_size=(512, 512),\n",
        "    class_mode='categorical',\n",
        "    batch_size=8,\n",
        "    shuffle=True\n",
        ")\n",
        "val_generator = datagen_val.flow_from_dataframe(\n",
        "    val_df,\n",
        "    directory=val_dir,\n",
        "    x_col='id_code',\n",
        "    y_col='diagnosis',\n",
        "    target_size=(512, 512),\n",
        "    class_mode='categorical',\n",
        "    batch_size=8,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "#  Class imbalance handling\n",
        "# ============================================================\n",
        "labels = train_df['diagnosis'].values\n",
        "class_weights_array = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(labels),\n",
        "    y=labels\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights_array))\n",
        "print(\"Class Weights:\", class_weights)\n",
        "\n",
        "# ============================================================\n",
        "# Resume training\n",
        "# ============================================================\n",
        "history_ft = fine_tune_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=15,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[checkpoint_ft, lr_scheduler_ft, early_stop_ft],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj1HL_adwIYa",
        "outputId": "da01b78b-59cf-4706-e293-57311bc09c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded from: /content/gdrive/My Drive/DR_Project/best_modelB_backup_before_finetune.keras\n",
            "Total trainable layers: 5\n",
            "Found 2929 validated image filenames belonging to 5 classes.\n",
            "Found 366 validated image filenames belonging to 5 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 1 invalid image filename(s) in x_col=\"id_code\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: np.float64(0.4086471408647141), 1: np.float64(1.9533333333333334), 2: np.float64(0.7252475247524752), 3: np.float64(3.8051948051948052), 4: np.float64(2.5042735042735043)}\n",
            "Epoch 1/15\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3803 - loss: 1.3760\n",
            "Epoch 1: val_accuracy improved from -inf to 0.65847, saving model to /content/gdrive/My Drive/DR_Project/best_modelB_finetuned.keras\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1585s\u001b[0m 4s/step - accuracy: 0.3807 - loss: 1.3758 - val_accuracy: 0.6585 - val_loss: 0.8087 - learning_rate: 1.0000e-05\n",
            "Epoch 2/15\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - accuracy: 0.6476 - loss: 1.1546\n",
            "Epoch 2: val_accuracy improved from 0.65847 to 0.68579, saving model to /content/gdrive/My Drive/DR_Project/best_modelB_finetuned.keras\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 616ms/step - accuracy: 0.6477 - loss: 1.1545 - val_accuracy: 0.6858 - val_loss: 0.7871 - learning_rate: 1.0000e-05\n",
            "Epoch 3/15\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step - accuracy: 0.6613 - loss: 1.1080\n",
            "Epoch 3: val_accuracy improved from 0.68579 to 0.69399, saving model to /content/gdrive/My Drive/DR_Project/best_modelB_finetuned.keras\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 623ms/step - accuracy: 0.6613 - loss: 1.1079 - val_accuracy: 0.6940 - val_loss: 0.7728 - learning_rate: 1.0000e-05\n",
            "Epoch 4/15\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607ms/step - accuracy: 0.6788 - loss: 1.0545\n",
            "Epoch 4: val_accuracy did not improve from 0.69399\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 624ms/step - accuracy: 0.6788 - loss: 1.0545 - val_accuracy: 0.6749 - val_loss: 0.7670 - learning_rate: 1.0000e-05\n",
            "Epoch 5/15\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.6900 - loss: 1.0192\n",
            "Epoch 5: val_accuracy improved from 0.69399 to 0.70492, saving model to /content/gdrive/My Drive/DR_Project/best_modelB_finetuned.keras\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 609ms/step - accuracy: 0.6900 - loss: 1.0192 - val_accuracy: 0.7049 - val_loss: 0.7272 - learning_rate: 1.0000e-05\n",
            "Epoch 6/15\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.7083 - loss: 1.0087\n",
            "Epoch 6: val_accuracy did not improve from 0.70492\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 615ms/step - accuracy: 0.7083 - loss: 1.0087 - val_accuracy: 0.6776 - val_loss: 0.7428 - learning_rate: 1.0000e-05\n",
            "Epoch 7/15\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584ms/step - accuracy: 0.7081 - loss: 0.9811\n",
            "Epoch 7: val_accuracy did not improve from 0.70492\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 598ms/step - accuracy: 0.7081 - loss: 0.9811 - val_accuracy: 0.6803 - val_loss: 0.7582 - learning_rate: 1.0000e-05\n",
            "Epoch 8/15\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.7024 - loss: 0.9770\n",
            "Epoch 8: val_accuracy did not improve from 0.70492\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 604ms/step - accuracy: 0.7024 - loss: 0.9769 - val_accuracy: 0.6803 - val_loss: 0.7636 - learning_rate: 1.0000e-05\n",
            "Epoch 9/15\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - accuracy: 0.6905 - loss: 0.9846\n",
            "Epoch 9: val_accuracy did not improve from 0.70492\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 597ms/step - accuracy: 0.6905 - loss: 0.9846 - val_accuracy: 0.6776 - val_loss: 0.7523 - learning_rate: 5.0000e-06\n",
            "Epoch 10/15\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597ms/step - accuracy: 0.7176 - loss: 0.9176\n",
            "Epoch 10: val_accuracy did not improve from 0.70492\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 614ms/step - accuracy: 0.7176 - loss: 0.9177 - val_accuracy: 0.6858 - val_loss: 0.7455 - learning_rate: 5.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "\n",
        "# include your custom layer if you used RBFLayer\n",
        "class RBFLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, gamma, **kwargs):\n",
        "        super(RBFLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.centers = self.add_weight(\n",
        "            name='centers',\n",
        "            shape=(self.units, int(input_shape[-1])),\n",
        "            initializer='uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        super(RBFLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        diff = tf.expand_dims(inputs, 1) - self.centers\n",
        "        return tf.exp(-self.gamma * tf.reduce_sum(tf.square(diff), axis=-1))\n",
        "\n",
        "# Load the finetuned model\n",
        "model_path = \"/content/gdrive/My Drive/DR_Project/best_modelB_finetuned.keras\"\n",
        "model = load_model(model_path, custom_objects={'RBFLayer': RBFLayer})\n",
        "print(\"Model loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7Djvi68DEuM",
        "outputId": "833c19d2-ee24-4476-d741-04cdb540e058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_dir = '/content/gdrive/My Drive/DR_Project/test_images/'\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(299, 299),   # same as training\n",
        "    batch_size=32,\n",
        "    class_mode='categorical', # or 'binary' if 2 classes\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb7S_PmoDI-_",
        "outputId": "f3fa78bd-bd73-4f7b-ce7f-fbc1b582a6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 366 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "base_path = \"/content/gdrive/My Drive/DR_Project/\"\n",
        "test_csv_path = base_path + \"test.csv\"\n",
        "test_dir = base_path + \"preprocessed_test/\"  # or your test folder\n",
        "\n",
        "test_df = pd.read_csv(test_csv_path)\n",
        "\n",
        "# Append .png if missing\n",
        "if not test_df['id_code'].iloc[0].endswith('.png'):\n",
        "    test_df['id_code'] = test_df['id_code'].astype(str) + \".png\"\n",
        "\n",
        "# Make sure diagnosis is string for categorical\n",
        "test_df[\"diagnosis\"] = test_df[\"diagnosis\"].astype(str)\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "Hb5SaPzdDnfF",
        "outputId": "8e573f3a-62a7-465a-fdce-91d2b0266864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/gdrive/My Drive/DR_Project/test.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-857474769.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"preprocessed_test/\"\u001b[0m  \u001b[0;31m# or your test folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_csv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Append .png if missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/DR_Project/test.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,         # DataFrame with columns [\"id_code\", \"diagnosis\"]\n",
        "    directory=test_dir,\n",
        "    x_col=\"id_code\",\n",
        "    y_col=\"diagnosis\",\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26FFo7oCDMMn",
        "outputId": "124ee8df-8a32-4d23-ef3c-c06d0eeaf6ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 366 validated image filenames belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,        # your test dataframe with id_code and diagnosis\n",
        "    directory=test_dir,       # folder with test images\n",
        "    x_col=\"id_code\",\n",
        "    y_col=\"diagnosis\",\n",
        "    target_size=(512, 512),   # same as model input\n",
        "    class_mode=\"categorical\", # or None if unlabeled\n",
        "    batch_size=8,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe6RVSZIEXmE",
        "outputId": "577f1c69-7501-4bd8-d96a-c70826ded12c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 366 validated image filenames belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Rebuild custom layer class (must match original exactly)\n",
        "class RBFLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, gamma, **kwargs):\n",
        "        super(RBFLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.centers = self.add_weight(\n",
        "            name='centers',\n",
        "            shape=(self.units, int(input_shape[-1])),\n",
        "            initializer='uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        super(RBFLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        diff = tf.expand_dims(inputs, 1) - self.centers\n",
        "        return tf.exp(-self.gamma * tf.reduce_sum(tf.square(diff), axis=-1))\n",
        "\n",
        "\n",
        "# Reload model freshly (don’t reuse in-memory graph)\n",
        "model_path = \"/content/gdrive/My Drive/DR_Project/best_modelB_finetuned.keras\"\n",
        "model = tf.keras.models.load_model(model_path, custom_objects={'RBFLayer': RBFLayer})\n",
        "\n",
        "print(\"Model reloaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HagrAjDxEu9a",
        "outputId": "548563b3-18d8-44bc-c3ea-b7552f0eddf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model reloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
        "print(f\"\\n✅ Test Accuracy: {test_acc*100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUq63k8XD0_L",
        "outputId": "09b954f0-8fe3-426e-a695-29776213f395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4s/step - accuracy: 0.7629 - loss: 0.6432\n",
            "\n",
            "✅ Test Accuracy: 76.23%\n",
            "Test Loss: 0.6580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns, matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Predict labels\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Per-class metrics\n",
        "print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "yH1w1YkEGFwu",
        "outputId": "03ee74b0-913a-46df-cb77-1a3bb0728f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 269ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       199\n",
            "           1       0.35      0.57      0.44        30\n",
            "           2       0.64      0.57      0.61        87\n",
            "           3       0.33      0.12      0.17        17\n",
            "           4       0.49      0.52      0.50        33\n",
            "\n",
            "    accuracy                           0.76       366\n",
            "   macro avg       0.56      0.55      0.54       366\n",
            "weighted avg       0.77      0.76      0.76       366\n",
            "\n"
          ]
        }
      ]
    }
  ]
}